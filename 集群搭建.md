# 集群搭建

## 配置host

在每台主机上修改host文件

```
vim /etc/hosts
```

```
# 添加各台主机信息
55.14.4.10 mdpt01kf
55.14.4.11 mdpt02kf
55.14.4.12 mdpt03kf
55.14.4.13 mdpt04kf
55.14.4.14 mdpt05kf
55.14.4.15 mdpt06kf
55.14.4.16 mdpt07kf
55.14.4.17 mdpt08kf
```

相互ping一下机器名，看是否生效。

## SSH免密码登陆

在所有机器上都生成私钥和公钥

```
ssh-keygen -t rsa
```

需要让机器之间能够相互访问，把每台机器上的公钥id_rsa.pub，通过scp发送给master节点。

```
scp /root/.ssh/id_rsa.pub qadmsom@mdpt01kf:/root/.ssh/id_rsa.pub.mdpt02kf
scp /root/.ssh/id_rsa.pub qadmsom@mdpt01kf:/root/.ssh/id_rsa.pub.mdpt03kf
scp /root/.ssh/id_rsa.pub qadmsom@mdpt01kf:/root/.ssh/id_rsa.pub.mdpt04kf
scp /root/.ssh/id_rsa.pub qadmsom@mdpt01kf:/root/.ssh/id_rsa.pub.mdpt05kf
scp /root/.ssh/id_rsa.pub qadmsom@mdpt01kf:/root/.ssh/id_rsa.pub.mdpt06kf
scp /root/.ssh/id_rsa.pub qadmsom@mdpt01kf:/root/.ssh/id_rsa.pub.mdpt07kf
scp /root/.ssh/id_rsa.pub qadmsom@mdpt01kf:/root/.ssh/id_rsa.pub.mdpt08kf
```

在master节点上，将所有的公钥加到用于认证的公钥文件authorized_keys中

```
cat ~/.ssh/id_rsa.pub* >> ~/.ssh/authorized_keys
```

将公钥文件authorized_keys分发给每台机器

```
scp /root/.ssh/authorized_keys qadmsom@mdpt02:/root/.ssh/
scp /root/.ssh/authorized_keys qadmsom@mdpt03:/root/.ssh/
scp /root/.ssh/authorized_keys qadmsom@mdpt04:/root/.ssh/
scp /root/.ssh/authorized_keys qadmsom@mdpt05:/root/.ssh/
scp /root/.ssh/authorized_keys qadmsom@mdpt06:/root/.ssh/
scp /root/.ssh/authorized_keys qadmsom@mdpt07:/root/.ssh/
scp /root/.ssh/authorized_keys qadmsom@mdpt08:/root/.ssh/
```

在每台机器上验证SSH无需密码通讯

```
ssh mdpt01kf
ssh mdpt02kf
ssh mdpt03kf
ssh mdpt04kf
ssh mdpt05kf
ssh mdpt06kf
ssh mdpt07kf
ssh mdpt08kf
```

## JVM环境配置

oracle下载jdk-8u281-linux-x64.tar.gz

通过scp分发到每个机器上，然后解压。

```
scp /opt/workspacce/jdk-8u281-linux-x64.tar.gz qadmsom@mdpt02:/opt/workspace/
tar -zxvf jdk-8u281-linux-x64.tar.gz
```

配置环境变量

```
vim /etc/profile

export WORK_SPACE=/opt/workspace
# Java
export JAVA_HOME=$WORK_SPACE/jdk1.8.0_281
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib
```

验证Java生效

```
source /etc/profile

java -version
```

## Scala配置

跟java类似

下载所需的scala版本，这里用的scala-2.12.13.

通过scp分发到每个机器上，然后解压。

```
scp /opt/workspacce/scala-2.12.13.tgz qadmsom@mdpt02:/opt/workspace/
tar -zxvf scala-2.12.13.tgz
```

配置环境变量

```
vim /etc/profile

# scala
export SCALA_HOME=$WORK_SPACE/scala-2.12.13
export PATH=$SCALA_HOME/bin
```

同样进行验证

## Hadoop配置

[官网](http://hadoop.apache.org/releases.html#Download)下载，这里下的是hadoop-3.3.0

同样在/opt/workspace中进行解压，

```
tar -zxvf hadoop-3.3.0.tar.gz
```

### 修改hadoop配置文件

cd hadoop-3.3.0/etc/hadoop，进入hadoop的配置目录，有7个文件需要配置修改：hadoop-env.sh，yarn-env.sh，workers，core-site.xml，hdfs-site.xml，maprd-site.xml，yarn-site.xml

1. 在`hadoop-env.sh`中配置JAVA_HOME等环境变量

   ```
   export JAVA_HOME=/opt/workspace/jdk1.8.0_281
   export HDFS_NAMENODE_USER=root
   export HDFS_DATANODE_USER=root
   export HDFS_SECONDARYNAMENODE_USER=root
   export HADOOP_SECURE_DN_USER=hdfs
   ```

2. 在`yarn-env.sh`中配置JAVA_HOME等环境变量

   ```
   export JAVA_HOME=/opt/workspace/jdk1.8.0_281
   export YARN_RESOURCEMANAGER_USER=root
   export YARN_NODEMANAGER_USER=root
   export HADOOP_SECURE_DN_USER=yarn
   ```

3. 在`workers`中配置worker节点的ip或者host

   ```
   mdpt01kf
   mdpt02kf
   mdpt03kf
   mdpt04kf
   mdpt05kf
   mdpt06kf
   mdpt07kf
   mdpt08kf
   ```

4. 修改`core-site.xml`

   ```xml
   <configuration>
       <property>
           <name>fs.defaultFS</name>
           <value>hdfs://mdpt01kf:9000/</value>
       </property>
       <property>
            <name>hadoop.tmp.dir</name>
            <value>/srv/BigData</value>
       </property>
   </configuration>
   ```

5. 修改`hdfs-site.xml`

   ```xml
   <configuration>
       <property>
           <name>dfs.namenode.secondary.http-address</name>
           <value>mdpt01kf:26001</value>
       </property>
       <property>
           <name>dfs.namenode.name.dir</name>
           <value>/srv/BigData/namenode</value>
       </property>
       <property>
           <name>dfs.datanode.data.dir</name>
           <value>/srv/BigData/datanode</value>
       </property>
       <property>
           <name>dfs.replication</name>
           <value>3</value>
       </property>
   </configuration>
   ```

6. 修改`mapred-site.xml`

   ```xml
   <configuration>
       <property>
           <name>mapreduce.framework.name</name>
           <value>yarn</value>
       </property>
   </configuration>
   ```

7. 修改`yarn-site.xml`

   ```xml
   <configuration>
       <property>
           <name>yarn.nodemanager.aux-services</name>
           <value>mapreduce_shuffle</value>
       </property>
       <property>
           <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
           <value>org.apache.hadoop.mapred.ShuffleHandler</value>
       </property>
       <property>
           <name>yarn.resourcemanager.address</name>
           <value>mdpt01kf:26010</value>
       </property>
       <property>
           <name>yarn.resourcemanager.scheduler.address</name>
           <value>mdpt01kf:26011</value>
       </property>
       <property>
           <name>yarn.resourcemanager.resource-tracker.address</name>
           <value>mdpt01kf:26012</value>
       </property>
       <property>
           <name>yarn.resourcemanager.admin.address</name>
           <value>mdpt01kf:26013</value>
       </property>
       <property>
           <name>yarn.resourcemanager.webapp.address</name>
           <value>mdpt01kf:26088</value>
       </property>
   </configuration>
   ```



在配置好所有文件后，hadoop-3.3.0文件夹打包，发送到其余的各个工作节点下， 再解压。

```sh
tar -zcvf hadoop.tar.gz hadoop-3.3.0
scp -r /opt/workspace/hadoop.tar.gz qadmsom@mdpt02kf:/opt/workspace/
scp -r /opt/workspace/hadoop.tar.gz qadmsom@mdpt03kf:/opt/workspace/
scp -r /opt/workspace/hadoop.tar.gz qadmsom@mdpt04kf:/opt/workspace/
scp -r /opt/workspace/hadoop.tar.gz qadmsom@mdpt05kf:/opt/workspace/
scp -r /opt/workspace/hadoop.tar.gz qadmsom@mdpt06kf:/opt/workspace/
scp -r /opt/workspace/hadoop.tar.gz qadmsom@mdpt07kf:/opt/workspace/
scp -r /opt/workspace/hadoop.tar.gz qadmsom@mdpt08kf:/opt/workspace/
```

### 启动Hadoop

在 master 上执行以下操作，就可以启动 hadoop 了。

```shell
bin/hadoop namenode -format     #格式化namenode
sbin/start-dfs.sh               #启动dfs 
sbin/start-yarn.sh              #启动yarn
```

验证hadoop

可以通过`jps`命令查看各个节点启动的进程是否正常。

master节点上会有进程：

```
SecondaryNameNode
NameNode
ResourceManager
```

在其余worker上会有节点：

```
NodeManager
DataNode
```

在本地浏览器中输入[http://55.14.4.10:26088](http://55.14.4.10:26088)，会有hadoop集群管理页面

![](assets/hadoop集群页面)

![](assets/hadoop节点页面)

## Spark配置

[spark下载页面](https://spark.apache.org/downloads.html)，下载spark-3.0.1-bin-without-hadoop.tgz

解压文件

```
tar -zxvf spark-3.0.1-bin-without-hadoop.tgz
mv spark-3.0.1-bin-without-hadoop spark-3.0.1
```

### 修改spark配置文件

```
cd /opt/workspace/spark-3.0.1/conf
cp spark-env.sh.template spark-env.sh   #从配置模板复制
vim spark-env.sh

# 添加环境变量
export SCALA_HOME=/opt/workspace/scala-2.12.13
export JAVA_HOME=/opt/workspace/jdk1.8.0_281
export HADOOP_HOME=/opt/workspace/hadoop-3.3.0
export HADOOP_CONF_DIR=$HADOOP/etc/hadoop
export SPARK_DIST_CLASSPATH=$(/opt/workspace/hadoop-3.3.0/bin/hadoop classpath)
SPARK_MASTER_IP=mdtp01kf
SPARK_LOCAL_DIR=/opt/workspace/spark-3.0.1
```

配置worker信息

```
cp slaves.template slaves
vim slaves

# 添加worker信息
mdpt01kf
mdpt02kf
mdpt03kf
mdpt04kf
mdpt05kf
mdpt06kf
mdpt07kf
mdpt08kf
```

将配置好的scala、spark文件夹压缩，发送到各个节点，解压。

### 启动Spark

在master节点上启动spark

```
sbin/start-all.sh
```

验证spark

用`jps`检查，在 master 上应该有以下几个进程：

```
Master
Worker
```

worker上只有：

```
Worker
```

在浏览器中输入[http://55.14.4.10:8080](http://55.14.4.10:8080)访问Spark页面：

![](assets/Spark页面)

运行Spark实例：

```sh
/opt/workspace/spark-3.0.1/bin/spark-submit \
  --class org.apache.spark.examples.SparkPi  \
  --master yarn  \
  --deploy-mode client \
  --driver-memory 4g  \
  --executor-memory 2g  \
  --executor-cores 1  \
  examples/jars/spark-examples*.jar  \
  10
```

![](assets/spark-pi-example1)

![](assets/spark-pi-example2)

